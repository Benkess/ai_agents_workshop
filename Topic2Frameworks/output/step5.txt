2026-01-21 23:30:44.187849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1769038244.214132    4541 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1769038244.219928    4541 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1769038244.235235    4541 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769038244.235265    4541 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769038244.235270    4541 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769038244.235273    4541 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-01-21 23:30:44.239764: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
==================================================
LangGraph Simple Agent with Llama-3.2-1B-Instruct
==================================================

Using CUDA (NVIDIA GPU) for inference
Loading model: meta-llama/Llama-3.2-1B-Instruct
This may take a moment on first run as the model is downloaded...
tokenizer_config.json: 100% 54.5k/54.5k [00:00<00:00, 1.22MB/s]
tokenizer.json: 100% 9.09M/9.09M [00:01<00:00, 8.34MB/s]
special_tokens_map.json: 100% 296/296 [00:00<00:00, 2.17MB/s]
config.json: 100% 877/877 [00:00<00:00, 6.94MB/s]
model.safetensors: 100% 2.47G/2.47G [00:22<00:00, 110MB/s] 
generation_config.json: 100% 189/189 [00:00<00:00, 1.44MB/s]
Device set to use cuda
Model loaded successfully!
Using CUDA (NVIDIA GPU) for inference
Loading Qwen model: Qwen/Qwen2.5-0.5B-Instruct
tokenizer_config.json: 7.30kB [00:00, 15.0MB/s]
vocab.json: 2.78MB [00:00, 160MB/s]
merges.txt: 1.67MB [00:00, 134MB/s]
tokenizer.json: 7.03MB [00:00, 204MB/s]
config.json: 100% 659/659 [00:00<00:00, 4.46MB/s]
model.safetensors: 100% 988M/988M [00:09<00:00, 107MB/s]
generation_config.json: 100% 242/242 [00:00<00:00, 2.34MB/s]
Device set to use cuda
Qwen model loaded successfully!

Creating LangGraph...
Graph created successfully!

Saving graph visualization...
Graph image saved to lg_graph.png

==================================================
Enter your text (or 'quit' to exit):
==================================================

> hi am testing chat history can you remember this word: flabbergasted

Processing input with Llama...

==================================================
Model Output:
==================================================

-- Llama Response --

I have stored the word "flabbergasted" in my database for future reference. I can recall it for you.

==================================================
Enter your text (or 'quit' to exit):
==================================================

> what was the word i asked you to remember?

Processing input with Llama...

==================================================
Model Output:
==================================================

-- Llama Response --

The word you asked me to remember is "flabbergasted".

==================================================
Enter your text (or 'quit' to exit):
==================================================

> quit
Goodbye!
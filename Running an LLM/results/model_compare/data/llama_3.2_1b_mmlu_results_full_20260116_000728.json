{
  "model": "meta-llama/Llama-3.2-1B-Instruct",
  "quantization_bits": null,
  "real_time_seconds": 607.826565,
  "cpu_time_seconds": 488.3365144730001,
  "gpu_time_seconds": 607.8305,
  "timestamp": "20260116_000728",
  "device": "cuda",
  "duration_seconds": 607.826565,
  "overall_accuracy": 46.38228172624982,
  "total_correct": 6513,
  "total_questions": 14042,
  "subject_results": [
    {
      "subject": "abstract_algebra",
      "correct": 24,
      "total": 100,
      "accuracy": 24.0
    },
    {
      "subject": "anatomy",
      "correct": 65,
      "total": 135,
      "accuracy": 48.148148148148145
    },
    {
      "subject": "astronomy",
      "correct": 75,
      "total": 152,
      "accuracy": 49.34210526315789
    },
    {
      "subject": "business_ethics",
      "correct": 45,
      "total": 100,
      "accuracy": 45.0
    },
    {
      "subject": "clinical_knowledge",
      "correct": 144,
      "total": 265,
      "accuracy": 54.339622641509436
    },
    {
      "subject": "college_biology",
      "correct": 76,
      "total": 144,
      "accuracy": 52.77777777777778
    },
    {
      "subject": "college_chemistry",
      "correct": 35,
      "total": 100,
      "accuracy": 35.0
    },
    {
      "subject": "college_computer_science",
      "correct": 26,
      "total": 100,
      "accuracy": 26.0
    },
    {
      "subject": "college_mathematics",
      "correct": 24,
      "total": 100,
      "accuracy": 24.0
    },
    {
      "subject": "college_medicine",
      "correct": 79,
      "total": 173,
      "accuracy": 45.664739884393065
    },
    {
      "subject": "college_physics",
      "correct": 17,
      "total": 102,
      "accuracy": 16.666666666666664
    },
    {
      "subject": "computer_security",
      "correct": 58,
      "total": 100,
      "accuracy": 57.99999999999999
    },
    {
      "subject": "conceptual_physics",
      "correct": 100,
      "total": 235,
      "accuracy": 42.5531914893617
    },
    {
      "subject": "econometrics",
      "correct": 30,
      "total": 114,
      "accuracy": 26.31578947368421
    },
    {
      "subject": "electrical_engineering",
      "correct": 75,
      "total": 145,
      "accuracy": 51.724137931034484
    },
    {
      "subject": "elementary_mathematics",
      "correct": 121,
      "total": 378,
      "accuracy": 32.01058201058201
    },
    {
      "subject": "formal_logic",
      "correct": 41,
      "total": 126,
      "accuracy": 32.53968253968254
    },
    {
      "subject": "global_facts",
      "correct": 31,
      "total": 100,
      "accuracy": 31.0
    },
    {
      "subject": "high_school_biology",
      "correct": 171,
      "total": 310,
      "accuracy": 55.16129032258065
    },
    {
      "subject": "high_school_chemistry",
      "correct": 75,
      "total": 203,
      "accuracy": 36.94581280788177
    },
    {
      "subject": "high_school_computer_science",
      "correct": 44,
      "total": 100,
      "accuracy": 44.0
    },
    {
      "subject": "high_school_european_history",
      "correct": 101,
      "total": 165,
      "accuracy": 61.212121212121204
    },
    {
      "subject": "high_school_geography",
      "correct": 112,
      "total": 198,
      "accuracy": 56.56565656565656
    },
    {
      "subject": "high_school_government_and_politics",
      "correct": 114,
      "total": 193,
      "accuracy": 59.067357512953365
    },
    {
      "subject": "high_school_macroeconomics",
      "correct": 153,
      "total": 390,
      "accuracy": 39.23076923076923
    },
    {
      "subject": "high_school_mathematics",
      "correct": 76,
      "total": 270,
      "accuracy": 28.14814814814815
    },
    {
      "subject": "high_school_microeconomics",
      "correct": 102,
      "total": 238,
      "accuracy": 42.857142857142854
    },
    {
      "subject": "high_school_physics",
      "correct": 35,
      "total": 151,
      "accuracy": 23.178807947019866
    },
    {
      "subject": "high_school_psychology",
      "correct": 343,
      "total": 545,
      "accuracy": 62.93577981651376
    },
    {
      "subject": "high_school_statistics",
      "correct": 59,
      "total": 216,
      "accuracy": 27.314814814814813
    },
    {
      "subject": "high_school_us_history",
      "correct": 118,
      "total": 204,
      "accuracy": 57.84313725490197
    },
    {
      "subject": "high_school_world_history",
      "correct": 150,
      "total": 237,
      "accuracy": 63.29113924050633
    },
    {
      "subject": "human_aging",
      "correct": 114,
      "total": 223,
      "accuracy": 51.12107623318386
    },
    {
      "subject": "human_sexuality",
      "correct": 76,
      "total": 131,
      "accuracy": 58.01526717557252
    },
    {
      "subject": "international_law",
      "correct": 74,
      "total": 121,
      "accuracy": 61.15702479338842
    },
    {
      "subject": "jurisprudence",
      "correct": 60,
      "total": 108,
      "accuracy": 55.55555555555556
    },
    {
      "subject": "logical_fallacies",
      "correct": 76,
      "total": 163,
      "accuracy": 46.62576687116564
    },
    {
      "subject": "machine_learning",
      "correct": 34,
      "total": 112,
      "accuracy": 30.357142857142854
    },
    {
      "subject": "management",
      "correct": 65,
      "total": 103,
      "accuracy": 63.10679611650486
    },
    {
      "subject": "marketing",
      "correct": 158,
      "total": 234,
      "accuracy": 67.52136752136752
    },
    {
      "subject": "medical_genetics",
      "correct": 59,
      "total": 100,
      "accuracy": 59.0
    },
    {
      "subject": "miscellaneous",
      "correct": 515,
      "total": 783,
      "accuracy": 65.77266922094508
    },
    {
      "subject": "moral_disputes",
      "correct": 162,
      "total": 346,
      "accuracy": 46.82080924855491
    },
    {
      "subject": "moral_scenarios",
      "correct": 291,
      "total": 895,
      "accuracy": 32.513966480446925
    },
    {
      "subject": "nutrition",
      "correct": 166,
      "total": 306,
      "accuracy": 54.248366013071895
    },
    {
      "subject": "philosophy",
      "correct": 160,
      "total": 311,
      "accuracy": 51.446945337620576
    },
    {
      "subject": "prehistory",
      "correct": 171,
      "total": 324,
      "accuracy": 52.77777777777778
    },
    {
      "subject": "professional_accounting",
      "correct": 90,
      "total": 282,
      "accuracy": 31.914893617021278
    },
    {
      "subject": "professional_law",
      "correct": 544,
      "total": 1534,
      "accuracy": 35.462842242503264
    },
    {
      "subject": "professional_medicine",
      "correct": 156,
      "total": 272,
      "accuracy": 57.35294117647059
    },
    {
      "subject": "professional_psychology",
      "correct": 257,
      "total": 612,
      "accuracy": 41.993464052287585
    },
    {
      "subject": "public_relations",
      "correct": 49,
      "total": 110,
      "accuracy": 44.54545454545455
    },
    {
      "subject": "security_studies",
      "correct": 130,
      "total": 245,
      "accuracy": 53.06122448979592
    },
    {
      "subject": "sociology",
      "correct": 122,
      "total": 201,
      "accuracy": 60.69651741293532
    },
    {
      "subject": "us_foreign_policy",
      "correct": 77,
      "total": 100,
      "accuracy": 77.0
    },
    {
      "subject": "virology",
      "correct": 76,
      "total": 166,
      "accuracy": 45.78313253012048
    },
    {
      "subject": "world_religions",
      "correct": 112,
      "total": 171,
      "accuracy": 65.49707602339181
    }
  ]
}
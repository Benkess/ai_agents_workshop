{
  "model": "allenai/Olmo-3-7B-Instruct",
  "quantization_bits": null,
  "real_time_seconds": 7270.587709,
  "cpu_time_seconds": 7162.936070966,
  "gpu_time_seconds": 7270.6515,
  "timestamp": "20260116_030218",
  "device": "cuda",
  "duration_seconds": 7270.587709,
  "overall_accuracy": 51.88719555618858,
  "total_correct": 7286,
  "total_questions": 14042,
  "subject_results": [
    {
      "subject": "abstract_algebra",
      "correct": 30,
      "total": 100,
      "accuracy": 30.0
    },
    {
      "subject": "anatomy",
      "correct": 67,
      "total": 135,
      "accuracy": 49.629629629629626
    },
    {
      "subject": "astronomy",
      "correct": 82,
      "total": 152,
      "accuracy": 53.94736842105263
    },
    {
      "subject": "business_ethics",
      "correct": 52,
      "total": 100,
      "accuracy": 52.0
    },
    {
      "subject": "clinical_knowledge",
      "correct": 161,
      "total": 265,
      "accuracy": 60.75471698113207
    },
    {
      "subject": "college_biology",
      "correct": 97,
      "total": 144,
      "accuracy": 67.36111111111111
    },
    {
      "subject": "college_chemistry",
      "correct": 37,
      "total": 100,
      "accuracy": 37.0
    },
    {
      "subject": "college_computer_science",
      "correct": 51,
      "total": 100,
      "accuracy": 51.0
    },
    {
      "subject": "college_mathematics",
      "correct": 27,
      "total": 100,
      "accuracy": 27.0
    },
    {
      "subject": "college_medicine",
      "correct": 94,
      "total": 173,
      "accuracy": 54.33526011560693
    },
    {
      "subject": "college_physics",
      "correct": 35,
      "total": 102,
      "accuracy": 34.31372549019608
    },
    {
      "subject": "computer_security",
      "correct": 54,
      "total": 100,
      "accuracy": 54.0
    },
    {
      "subject": "conceptual_physics",
      "correct": 104,
      "total": 235,
      "accuracy": 44.25531914893617
    },
    {
      "subject": "econometrics",
      "correct": 42,
      "total": 114,
      "accuracy": 36.84210526315789
    },
    {
      "subject": "electrical_engineering",
      "correct": 55,
      "total": 145,
      "accuracy": 37.93103448275862
    },
    {
      "subject": "elementary_mathematics",
      "correct": 121,
      "total": 378,
      "accuracy": 32.01058201058201
    },
    {
      "subject": "formal_logic",
      "correct": 54,
      "total": 126,
      "accuracy": 42.857142857142854
    },
    {
      "subject": "global_facts",
      "correct": 31,
      "total": 100,
      "accuracy": 31.0
    },
    {
      "subject": "high_school_biology",
      "correct": 209,
      "total": 310,
      "accuracy": 67.41935483870968
    },
    {
      "subject": "high_school_chemistry",
      "correct": 79,
      "total": 203,
      "accuracy": 38.91625615763547
    },
    {
      "subject": "high_school_computer_science",
      "correct": 62,
      "total": 100,
      "accuracy": 62.0
    },
    {
      "subject": "high_school_european_history",
      "correct": 80,
      "total": 165,
      "accuracy": 48.484848484848484
    },
    {
      "subject": "high_school_geography",
      "correct": 135,
      "total": 198,
      "accuracy": 68.18181818181817
    },
    {
      "subject": "high_school_government_and_politics",
      "correct": 156,
      "total": 193,
      "accuracy": 80.82901554404145
    },
    {
      "subject": "high_school_macroeconomics",
      "correct": 190,
      "total": 390,
      "accuracy": 48.717948717948715
    },
    {
      "subject": "high_school_mathematics",
      "correct": 67,
      "total": 270,
      "accuracy": 24.814814814814813
    },
    {
      "subject": "high_school_microeconomics",
      "correct": 150,
      "total": 238,
      "accuracy": 63.02521008403361
    },
    {
      "subject": "high_school_physics",
      "correct": 64,
      "total": 151,
      "accuracy": 42.384105960264904
    },
    {
      "subject": "high_school_psychology",
      "correct": 389,
      "total": 545,
      "accuracy": 71.37614678899082
    },
    {
      "subject": "high_school_statistics",
      "correct": 89,
      "total": 216,
      "accuracy": 41.2037037037037
    },
    {
      "subject": "high_school_us_history",
      "correct": 123,
      "total": 204,
      "accuracy": 60.29411764705882
    },
    {
      "subject": "high_school_world_history",
      "correct": 142,
      "total": 237,
      "accuracy": 59.91561181434599
    },
    {
      "subject": "human_aging",
      "correct": 120,
      "total": 223,
      "accuracy": 53.81165919282511
    },
    {
      "subject": "human_sexuality",
      "correct": 85,
      "total": 131,
      "accuracy": 64.8854961832061
    },
    {
      "subject": "international_law",
      "correct": 83,
      "total": 121,
      "accuracy": 68.59504132231406
    },
    {
      "subject": "jurisprudence",
      "correct": 68,
      "total": 108,
      "accuracy": 62.96296296296296
    },
    {
      "subject": "logical_fallacies",
      "correct": 105,
      "total": 163,
      "accuracy": 64.41717791411043
    },
    {
      "subject": "machine_learning",
      "correct": 46,
      "total": 112,
      "accuracy": 41.07142857142857
    },
    {
      "subject": "management",
      "correct": 67,
      "total": 103,
      "accuracy": 65.0485436893204
    },
    {
      "subject": "marketing",
      "correct": 173,
      "total": 234,
      "accuracy": 73.93162393162393
    },
    {
      "subject": "medical_genetics",
      "correct": 61,
      "total": 100,
      "accuracy": 61.0
    },
    {
      "subject": "miscellaneous",
      "correct": 545,
      "total": 783,
      "accuracy": 69.60408684546616
    },
    {
      "subject": "moral_disputes",
      "correct": 199,
      "total": 346,
      "accuracy": 57.51445086705203
    },
    {
      "subject": "moral_scenarios",
      "correct": 247,
      "total": 895,
      "accuracy": 27.59776536312849
    },
    {
      "subject": "nutrition",
      "correct": 162,
      "total": 306,
      "accuracy": 52.94117647058824
    },
    {
      "subject": "philosophy",
      "correct": 194,
      "total": 311,
      "accuracy": 62.37942122186495
    },
    {
      "subject": "prehistory",
      "correct": 200,
      "total": 324,
      "accuracy": 61.72839506172839
    },
    {
      "subject": "professional_accounting",
      "correct": 120,
      "total": 282,
      "accuracy": 42.5531914893617
    },
    {
      "subject": "professional_law",
      "correct": 554,
      "total": 1534,
      "accuracy": 36.11473272490222
    },
    {
      "subject": "professional_medicine",
      "correct": 163,
      "total": 272,
      "accuracy": 59.92647058823529
    },
    {
      "subject": "professional_psychology",
      "correct": 339,
      "total": 612,
      "accuracy": 55.392156862745104
    },
    {
      "subject": "public_relations",
      "correct": 70,
      "total": 110,
      "accuracy": 63.63636363636363
    },
    {
      "subject": "security_studies",
      "correct": 155,
      "total": 245,
      "accuracy": 63.26530612244898
    },
    {
      "subject": "sociology",
      "correct": 146,
      "total": 201,
      "accuracy": 72.636815920398
    },
    {
      "subject": "us_foreign_policy",
      "correct": 74,
      "total": 100,
      "accuracy": 74.0
    },
    {
      "subject": "virology",
      "correct": 73,
      "total": 166,
      "accuracy": 43.97590361445783
    },
    {
      "subject": "world_religions",
      "correct": 108,
      "total": 171,
      "accuracy": 63.1578947368421
    }
  ]
}